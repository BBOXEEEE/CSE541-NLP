{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f316cbcfb90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4\"  # define device ids to use before importing torch\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tdocument\tlabel\n",
      "\n",
      "9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n",
      "\n",
      "3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n",
      "\n",
      "10265843\t너무재밓었다그래서보는것을추천한다\t0\n",
      "\n",
      "9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "\n",
    "# download files for sentiment classification\n",
    "def download(url, filename):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        response = get(url)\n",
    "        file.write(response.content)\n",
    "\n",
    "download(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", \"ratings_train.txt\")\n",
    "download(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", \"ratings_test.txt\")\n",
    "\n",
    "with open(\"ratings_train.txt\", \"r\") as file:\n",
    "    for i in range(5):\n",
    "        print(file.readline())\n",
    "\n",
    "with open(\"ratings_train.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    contents = file.read()\n",
    "    lines = contents.split(\"\\n\")[1:]\n",
    "    train_data = [line.split(\"\\t\") for line in lines if len(line) > 0]\n",
    "\n",
    "with open(\"ratings_test.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    contents = file.read()\n",
    "    lines = contents.split(\"\\n\")[1:]\n",
    "    test_data = [line.split(\"\\t\") for line in lines if len(line) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "tokenizer = lambda x: x.split()\n",
    "\n",
    "tokenized_train_dataset = []\n",
    "tokenized_test_dataset = []\n",
    "\n",
    "# remove unnecessary chracaters\n",
    "for data in train_data:\n",
    "    text = re.sub(r'[,.!?;:()\\\"\\'-]', ' ', data[1])\n",
    "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]', ' ', text)\n",
    "    tokens = tokenizer(text)\n",
    "    labels = data[2]\n",
    "    tokenized_train_dataset.append((tokens, labels))\n",
    "\n",
    "for data in test_data:\n",
    "    text = re.sub(r'[,.!?;:()\\\"\\'-]', ' ', data[1])\n",
    "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]', ' ', text)\n",
    "    tokens = tokenizer(text)\n",
    "    labels = data[2]\n",
    "    tokenized_test_dataset.append((tokens, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "token_counter = Counter()\n",
    "\n",
    "for tokens, _ in tokenized_train_dataset:\n",
    "    token_counter.update(tokens)\n",
    "\n",
    "# remove tokens that appear only twice or less\n",
    "min_count = 2\n",
    "cleaned_vocab = {\"[PAD]\":0, \"[UNK]\":1}\n",
    "cleaned_vocab_idx = 2\n",
    "\n",
    "for token, count in token_counter.items():\n",
    "    if count > min_count:\n",
    "        cleaned_vocab[token] = cleaned_vocab_idx\n",
    "        cleaned_vocab_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['아', '더빙', '진짜', '짜증나네요', '목소리'],\n",
       " ['흠', '포스터보고', '초딩영화줄', '오버연기조차', '가볍지', '않구나'],\n",
       " ['너무재밓었다그래서보는것을추천한다'],\n",
       " ['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정'],\n",
       " ['사이몬페그의',\n",
       "  '익살스런',\n",
       "  '연기가',\n",
       "  '돋보였던',\n",
       "  '영화',\n",
       "  '스파이더맨에서',\n",
       "  '늙어보이기만',\n",
       "  '했던',\n",
       "  '커스틴',\n",
       "  '던스트가',\n",
       "  '너무나도',\n",
       "  '이뻐보였다']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make word2vec train data\n",
    "word2vec_train_datas = []\n",
    "for train_text, _ in tokenized_train_dataset:\n",
    "    word2vec_train_datas.append([word for word in train_text])\n",
    "\n",
    "word2vec_train_datas[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# call CBOW or SkipGram\n",
    "# CBOW_W2V = Word2Vec(sentences = word2vec_train_datas, vector_size = 32, window = 5, min_count = 1, workers = 4, sg = 0)\n",
    "SkipGram_W2V = Word2Vec(sentences = word2vec_train_datas, vector_size = 32, window = 5, min_count = 1, workers = 4, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43354, 32)\n",
      "43354\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# make embedding lookup matrix\n",
    "embedding_list = []\n",
    "\n",
    "for token, idx in cleaned_vocab.items():\n",
    "    if token in SkipGram_W2V.wv:\n",
    "        embedding_list.append(SkipGram_W2V.wv[token])\n",
    "    elif token == \"[PAD]\":\n",
    "        embedding_list.append(np.zeros(SkipGram_W2V.wv.vectors.shape[1]))\n",
    "    elif token == \"[UNK]\":\n",
    "        embedding_list.append(np.random.uniform(-1, 1, SkipGram_W2V.wv.vectors.shape[1]))\n",
    "    else:\n",
    "        embedding_list.append(np.random.uniform(-1, 1, SkipGram_W2V.wv.vectors.shape[1]))\n",
    "\n",
    "embedding_loopup_matrix = np.vstack(embedding_list)\n",
    "\n",
    "print(embedding_loopup_matrix.shape)    # (43354, 32)\n",
    "print(len(cleaned_vocab))               # 43354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# define dataset class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, data, vocab):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.data[index][1])\n",
    "        tokens = self.data[index][0]\n",
    "\n",
    "        token_ids = [self.vocab[token] if token in self.vocab else 1 for token in tokens]\n",
    "        \n",
    "        # Text는 데이터 별로 길이가 다르다.\n",
    "        # 100은 sequence의 길이를 임의로 설정한 것\n",
    "        # 100 token보다 길이가 긴 것은 100 token으로 자르기!\n",
    "        # 100 token보다 길이가 짧은 것은 PAD token을 뒤에 추가!\n",
    "        # --> 길이가 같은 vector를 모아 matrix를 만들기 위함! (GPU 연산을 위해)\n",
    "        if len(token_ids) > 100:\n",
    "            token_ids = token_ids[:100]\n",
    "        else:\n",
    "            token_ids = token_ids[:100] + [0] * (100 - len(token_ids))\n",
    "\n",
    "        return torch.tensor(token_ids), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import lightning as pl\n",
    "\n",
    "class SentimentClassifierPL(pl.LightningModule):\n",
    "    def __init__(self, sentiment_classifier):\n",
    "        super(SentimentClassifierPL, self).__init__()\n",
    "        self.model = sentiment_classifier\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss(outputs, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss(outputs, labels)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.validation_step_outputs.append((loss, outputs, labels))\n",
    "        return loss, outputs, labels\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        outputs = self.validation_step_outputs\n",
    "        avg_loss = torch.stack([x[0] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        \n",
    "        all_outputs = torch.cat([x[1] for x in outputs])\n",
    "        all_labels = torch.cat([x[2] for x in outputs])\n",
    "        all_preds = all_outputs.argmax(dim=1)\n",
    "        accuracy = (all_preds == all_labels).float().mean()\n",
    "        self.log(\"val_accuracy\", accuracy)\n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss(outputs, labels)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.test_step_outputs.append((loss, outputs, labels))\n",
    "        return loss, outputs, labels\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        outputs = self.test_step_outputs\n",
    "        avg_loss = torch.stack([x[0] for x in outputs]).mean()\n",
    "        self.log(\"avg_test_loss\", avg_loss)\n",
    "        \n",
    "        all_outputs = torch.cat([x[1] for x in outputs])\n",
    "        all_labels = torch.cat([x[2] for x in outputs])\n",
    "        all_preds = all_outputs.argmax(dim=1)\n",
    "        accuracy = (all_preds == all_labels).float().mean()\n",
    "        self.log(\"test_accuracy\", accuracy)\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnoeyhesx\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "def check_vocab_properties(vocab):\n",
    "    print(f\"Vocab size: {len(vocab)}\")\n",
    "    print(f\"Vocab items: {list(vocab.items())[:5]}\")\n",
    "\n",
    "\n",
    "def check_performance(model, vocab,train_data, test_data, wandb_log_name):\n",
    "    wandb_logger = WandbLogger(project=\"NLP\", name=wandb_log_name, group=\"Lec04\")\n",
    "\n",
    "    pl_model = SentimentClassifierPL(model)\n",
    "\n",
    "    train_dataset = SentimentDataset(train_data, vocab)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "    val_dataset = SentimentDataset(test_data, vocab)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "    test_dataset = SentimentDataset(test_data, vocab)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=3,\n",
    "        accelerator=\"gpu\",\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[ModelSummary(max_depth=2)]\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        model=pl_model,\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=val_loader\n",
    "    )\n",
    "\n",
    "    trainer.test(dataloaders=test_loader)\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_loopup_matrix), freeze=False)\n",
    "        self.fc1 = nn.Linear(32 * 100, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        x = self.embedding(x)\n",
    "        print(x.size())\n",
    "        x = x.view(-1, 32 * 100)\n",
    "        print(x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.SG_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_loopup_matrix), freeze=True)\n",
    "        self.RD_embedding = nn.Embedding(vocab_size, 32)\n",
    "        \n",
    "        self.SG_conv1 = nn.Conv2d(1, 32, (3, 32))\n",
    "        self.SG_conv2 = nn.Conv2d(1, 32, (4, 32))\n",
    "        self.SG_conv3 = nn.Conv2d(1, 32, (5, 32))\n",
    "        \n",
    "        self.RD_conv1 = nn.Conv2d(1, 32, (3, 32))\n",
    "        self.RD_conv2 = nn.Conv2d(1, 32, (4, 32))\n",
    "        self.RD_conv3 = nn.Conv2d(1, 32, (5, 32))\n",
    "        \n",
    "        self.fc = nn.Linear(6*32, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        SG_embedding = self.SG_embedding(x).unsqueeze(1)\n",
    "        print(SG_embedding.size())\n",
    "        RD_embedding = self.RD_embedding(x).unsqueeze(1)\n",
    "\n",
    "        SG_conv1_feature = F.relu(self.SG_conv1(SG_embedding).squeeze(3))\n",
    "        print(SG_conv1_feature.size())\n",
    "        SG_conv2_feature = F.relu(self.SG_conv2(SG_embedding).squeeze(3))\n",
    "        print(SG_conv2_feature.size())\n",
    "        SG_conv3_feature = F.relu(self.SG_conv3(SG_embedding).squeeze(3))\n",
    "                                                                         \n",
    "        RD_conv1_feature = F.relu(self.RD_conv1(RD_embedding).squeeze(3))\n",
    "        RD_conv2_feature = F.relu(self.RD_conv2(RD_embedding).squeeze(3))\n",
    "        RD_conv3_feature = F.relu(self.RD_conv3(RD_embedding).squeeze(3))\n",
    "\n",
    "        SG_max1 = F.max_pool1d(SG_conv1_feature, SG_conv1_feature.size(2)).squeeze(2)\n",
    "        print(SG_max1.size())\n",
    "        SG_max2 = F.max_pool1d(SG_conv2_feature, SG_conv2_feature.size(2)).squeeze(2)  \n",
    "        SG_max3 = F.max_pool1d(SG_conv3_feature, SG_conv3_feature.size(2)).squeeze(2)  \n",
    "\n",
    "        RD_max1 = F.max_pool1d(RD_conv1_feature, RD_conv1_feature.size(2)).squeeze(2)  \n",
    "        RD_max2 = F.max_pool1d(RD_conv2_feature, RD_conv2_feature.size(2)).squeeze(2)  \n",
    "        RD_max3 = F.max_pool1d(RD_conv3_feature, RD_conv3_feature.size(2)).squeeze(2)  \n",
    "\n",
    "        x = torch.cat([SG_max1, SG_max2, SG_max3, RD_max1, RD_max2, RD_max3], dim=1)\n",
    "        print(x.size())\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        hidden_size = 32\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_loopup_matrix), freeze=False)\n",
    "        self.rnn = nn.LSTM(32, 32, batch_first=True, num_layers=2, bidirectional=False)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        print(x.size())\n",
    "        x, _ = self.rnn(x)\n",
    "        print(x.size())\n",
    "        x = x.mean(dim=1)\n",
    "        print(x.size())\n",
    "        # x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class biLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(biLSTM, self).__init__()\n",
    "        hidden_size = 32\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_loopup_matrix), freeze=False)\n",
    "        self.rnn = nn.LSTM(32, 32, batch_first=True, num_layers=2, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size * 2, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = x.mean(dim=1)\n",
    "        # x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(len(cleaned_vocab))\n",
    "textcnn_model = TextCNN(len(cleaned_vocab))\n",
    "lstm_model = LSTM(len(cleaned_vocab))\n",
    "bilstm_model = biLSTM(len(cleaned_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = torch.randint(0, len(cleaned_vocab), (2, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100])\n",
      "torch.Size([2, 100, 32])\n",
      "torch.Size([2, 3200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1286,  0.1403],\n",
       "        [-0.0881,  0.1116]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.forward(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 100, 32])\n",
      "torch.Size([2, 32, 98])\n",
      "torch.Size([2, 32, 97])\n",
      "torch.Size([2, 32])\n",
      "torch.Size([2, 192])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9387, 0.3004],\n",
       "        [1.2668, 0.2256]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcnn_model.forward(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 32])\n",
      "torch.Size([2, 100, 32])\n",
      "torch.Size([2, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0004, -0.0427],\n",
       "        [-0.0006, -0.0425]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.forward(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0201, 0.0343],\n",
       "        [0.0200, 0.0347]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_model.forward(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'sentiment_classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['sentiment_classifier'])`.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240403_114909-eukokczm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/noeyhesx/NLP/runs/eukokczm/workspace' target=\"_blank\">mlp</a></strong> to <a href='https://wandb.ai/noeyhesx/NLP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/noeyhesx/NLP' target=\"_blank\">https://wandb.ai/noeyhesx/NLP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/noeyhesx/NLP/runs/eukokczm/workspace' target=\"_blank\">https://wandb.ai/noeyhesx/NLP/runs/eukokczm/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params\n",
      "-----------------------------------------------------\n",
      "0 | model           | MLP              | 1.7 M \n",
      "1 | model.embedding | Embedding        | 1.4 M \n",
      "2 | model.fc1       | Linear           | 320 K \n",
      "3 | model.fc2       | Linear           | 202   \n",
      "4 | loss            | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.831     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2344/2344 [00:06<00:00, 335.60it/s, v_num=kczm]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2344/2344 [00:07<00:00, 333.97it/s, v_num=kczm]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at ./NLP/eukokczm/checkpoints/epoch=2-step=7032.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./NLP/eukokczm/checkpoints/epoch=2-step=7032.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 782/782 [00:01<00:00, 730.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      avg_test_loss         0.4086398482322693\n",
      "      test_accuracy         0.8113200068473816\n",
      "        test_loss           0.40860047936439514\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>▁</td></tr><tr><td>avg_val_loss</td><td>▁▁█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▆▄▃▅▆▅▅▄▄▃▄▄▄▃▃▃▄▂▂▄▃▃▆▄▄▁▃▃▃▄▃▂▁▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_accuracy</td><td>▅█▁</td></tr><tr><td>val_loss</td><td>▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>0.40864</td></tr><tr><td>avg_val_loss</td><td>0.40864</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>test_accuracy</td><td>0.81132</td></tr><tr><td>test_loss</td><td>0.4086</td></tr><tr><td>train_loss</td><td>0.24202</td></tr><tr><td>trainer/global_step</td><td>7032</td></tr><tr><td>val_accuracy</td><td>0.81132</td></tr><tr><td>val_loss</td><td>0.4086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mlp</strong> at: <a href='https://wandb.ai/noeyhesx/NLP/runs/eukokczm/workspace' target=\"_blank\">https://wandb.ai/noeyhesx/NLP/runs/eukokczm/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240403_114909-eukokczm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_performance(mlp_model, cleaned_vocab, tokenized_train_dataset, tokenized_test_dataset, \"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'sentiment_classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['sentiment_classifier'])`.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240403_115002-3onpf41c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/noeyhesx/NLP/runs/3onpf41c/workspace' target=\"_blank\">textcnn</a></strong> to <a href='https://wandb.ai/noeyhesx/NLP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/noeyhesx/NLP' target=\"_blank\">https://wandb.ai/noeyhesx/NLP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/noeyhesx/NLP/runs/3onpf41c/workspace' target=\"_blank\">https://wandb.ai/noeyhesx/NLP/runs/3onpf41c/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name               | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0  | model              | TextCNN          | 2.8 M \n",
      "1  | model.SG_embedding | Embedding        | 1.4 M \n",
      "2  | model.RD_embedding | Embedding        | 1.4 M \n",
      "3  | model.SG_conv1     | Conv2d           | 3.1 K \n",
      "4  | model.SG_conv2     | Conv2d           | 4.1 K \n",
      "5  | model.SG_conv3     | Conv2d           | 5.2 K \n",
      "6  | model.RD_conv1     | Conv2d           | 3.1 K \n",
      "7  | model.RD_conv2     | Conv2d           | 4.1 K \n",
      "8  | model.RD_conv3     | Conv2d           | 5.2 K \n",
      "9  | model.fc           | Linear           | 386   \n",
      "10 | loss               | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "1.4 M     Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.199    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2344/2344 [00:08<00:00, 263.15it/s, v_num=f41c]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2344/2344 [00:08<00:00, 261.83it/s, v_num=f41c]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at ./NLP/3onpf41c/checkpoints/epoch=2-step=7032.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./NLP/3onpf41c/checkpoints/epoch=2-step=7032.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 782/782 [00:01<00:00, 662.27it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      avg_test_loss         0.45426586270332336\n",
      "      test_accuracy         0.7851199507713318\n",
      "        test_loss           0.4540354013442993\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>▁</td></tr><tr><td>avg_val_loss</td><td>▆▁█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>▇▆▅▄▅▅▅▄▄▅▆▅█▄▅▄▃▃▄▅▅▄▇▅▄▃▄▅▄▄▅▃▆▃▄▅▅▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_accuracy</td><td>▁▇█</td></tr><tr><td>val_loss</td><td>▆▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>0.45427</td></tr><tr><td>avg_val_loss</td><td>0.45427</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>test_accuracy</td><td>0.78512</td></tr><tr><td>test_loss</td><td>0.45404</td></tr><tr><td>train_loss</td><td>0.21696</td></tr><tr><td>trainer/global_step</td><td>7032</td></tr><tr><td>val_accuracy</td><td>0.78512</td></tr><tr><td>val_loss</td><td>0.45404</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">textcnn</strong> at: <a href='https://wandb.ai/noeyhesx/NLP/runs/3onpf41c/workspace' target=\"_blank\">https://wandb.ai/noeyhesx/NLP/runs/3onpf41c/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240403_115002-3onpf41c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_performance(textcnn_model, cleaned_vocab, tokenized_train_dataset, tokenized_test_dataset, \"textcnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'sentiment_classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['sentiment_classifier'])`.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240403_115051-mey8azlo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/noeyhesx/NLP/runs/mey8azlo/workspace' target=\"_blank\">lstm</a></strong> to <a href='https://wandb.ai/noeyhesx/NLP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/noeyhesx/NLP' target=\"_blank\">https://wandb.ai/noeyhesx/NLP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/noeyhesx/NLP/runs/mey8azlo/workspace' target=\"_blank\">https://wandb.ai/noeyhesx/NLP/runs/mey8azlo/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params\n",
      "-----------------------------------------------------\n",
      "0 | model           | LSTM             | 1.4 M \n",
      "1 | model.embedding | Embedding        | 1.4 M \n",
      "2 | model.rnn       | LSTM             | 16.9 K\n",
      "3 | model.fc        | Sequential       | 1.1 K \n",
      "4 | loss            | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.621     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2344/2344 [00:08<00:00, 270.86it/s, v_num=azlo]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2344/2344 [00:08<00:00, 269.88it/s, v_num=azlo]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at ./NLP/mey8azlo/checkpoints/epoch=2-step=7032.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./NLP/mey8azlo/checkpoints/epoch=2-step=7032.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 782/782 [00:01<00:00, 653.67it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      avg_test_loss         0.39808112382888794\n",
      "      test_accuracy         0.8160799741744995\n",
      "        test_loss           0.39798110723495483\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>▁</td></tr><tr><td>avg_val_loss</td><td>█▁▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▆████▇▇▇▆▄▆▃▃▄▂▂▃▃▃▃▃▂▃▄▃▁▂▄▂▂▂▃▂▄▂▄▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_accuracy</td><td>▁█▇</td></tr><tr><td>val_loss</td><td>█▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>0.39808</td></tr><tr><td>avg_val_loss</td><td>0.39808</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>test_accuracy</td><td>0.81608</td></tr><tr><td>test_loss</td><td>0.39798</td></tr><tr><td>train_loss</td><td>0.29177</td></tr><tr><td>trainer/global_step</td><td>7032</td></tr><tr><td>val_accuracy</td><td>0.81608</td></tr><tr><td>val_loss</td><td>0.39798</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lstm</strong> at: <a href='https://wandb.ai/noeyhesx/NLP/runs/mey8azlo/workspace' target=\"_blank\">https://wandb.ai/noeyhesx/NLP/runs/mey8azlo/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240403_115051-mey8azlo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_performance(lstm_model, cleaned_vocab, tokenized_train_dataset, tokenized_test_dataset, \"lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'sentiment_classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['sentiment_classifier'])`.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240403_115137-aojg439z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/noeyhesx/NLP/runs/aojg439z/workspace' target=\"_blank\">bilstm</a></strong> to <a href='https://wandb.ai/noeyhesx/NLP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/noeyhesx/NLP' target=\"_blank\">https://wandb.ai/noeyhesx/NLP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/noeyhesx/NLP/runs/aojg439z/workspace' target=\"_blank\">https://wandb.ai/noeyhesx/NLP/runs/aojg439z/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params\n",
      "-----------------------------------------------------\n",
      "0 | model           | biLSTM           | 1.4 M \n",
      "1 | model.embedding | Embedding        | 1.4 M \n",
      "2 | model.rnn       | LSTM             | 42.0 K\n",
      "3 | model.fc        | Sequential       | 4.3 K \n",
      "4 | loss            | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.734     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2344/2344 [00:09<00:00, 253.96it/s, v_num=439z]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2344/2344 [00:09<00:00, 253.11it/s, v_num=439z]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/nlp/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at ./NLP/aojg439z/checkpoints/epoch=2-step=7032.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./NLP/aojg439z/checkpoints/epoch=2-step=7032.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 782/782 [00:01<00:00, 659.51it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      avg_test_loss         0.40379056334495544\n",
      "      test_accuracy         0.8178199529647827\n",
      "        test_loss           0.4034873843193054\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>▁</td></tr><tr><td>avg_val_loss</td><td>▇▁█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>▇▄▇▅▄▅▅▅▅▅▃▄▅▄▄▃▃▃▃▂▃▃▂▃▃▂▁▂▄▂▃▁▂▄▁▁▃█▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_accuracy</td><td>▁██</td></tr><tr><td>val_loss</td><td>▇▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_test_loss</td><td>0.40379</td></tr><tr><td>avg_val_loss</td><td>0.40379</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>test_accuracy</td><td>0.81782</td></tr><tr><td>test_loss</td><td>0.40349</td></tr><tr><td>train_loss</td><td>0.43375</td></tr><tr><td>trainer/global_step</td><td>7032</td></tr><tr><td>val_accuracy</td><td>0.81782</td></tr><tr><td>val_loss</td><td>0.40349</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bilstm</strong> at: <a href='https://wandb.ai/noeyhesx/NLP/runs/aojg439z/workspace' target=\"_blank\">https://wandb.ai/noeyhesx/NLP/runs/aojg439z/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240403_115137-aojg439z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_performance(bilstm_model, cleaned_vocab, tokenized_train_dataset, tokenized_test_dataset, \"bilstm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
