{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download files for sentiment classification\n",
    "from requests import get\n",
    "\n",
    "def download(url, filename):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        response = get(url)\n",
    "        file.write(response.content)\n",
    "\n",
    "download(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", \"ratings_train.txt\")\n",
    "download(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", \"ratings_test.txt\")\n",
    "\n",
    "# print first 5 lines of the file\n",
    "with open(\"ratings_train.txt\", \"r\") as file:\n",
    "    for i in range(5):\n",
    "        print(file.readline())\n",
    "        \n",
    "# build a vocabulary with training data\n",
    "with open(\"ratings_train.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    contents = file.read()\n",
    "    lines = contents.split(\"\\n\")[1:]\n",
    "    train_data = [line.split(\"\\t\") for line in lines if len(line) > 0]\n",
    "\n",
    "with open(\"ratings_test.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    contents = file.read()\n",
    "    lines = contents.split(\"\\n\")[1:]\n",
    "    test_data = [line.split(\"\\t\") for line in lines if len(line) > 0]\n",
    "\n",
    "vocab = {\"[PAD]\":0, \"[UNK]\":1}\n",
    "vocab_idx = 2\n",
    "for data in train_data:\n",
    "    line = data[1]\n",
    "    for char in line:\n",
    "        if char not in vocab:\n",
    "            vocab[char] = vocab_idx\n",
    "            vocab_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 32)\n",
    "        self.fc1 = nn.Linear(32 * 100, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(-1, 32 * 100)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "\n",
    "class SentimentClassifierPL(pl.LightningModule):\n",
    "    def __init__(self, sentiment_classifier):\n",
    "        super(SentimentClassifierPL, self).__init__()\n",
    "        self.model = sentiment_classifier\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss(outputs, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss(outputs, labels)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.validation_step_outputs.append((loss, outputs, labels))\n",
    "        return loss, outputs, labels\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        outputs = self.validation_step_outputs\n",
    "        avg_loss = torch.stack([x[0] for x in outputs]).mean()\n",
    "        self.log(\"avg_val_loss\", avg_loss)\n",
    "        \n",
    "        all_outputs = torch.cat([x[1] for x in outputs])\n",
    "        all_labels = torch.cat([x[2] for x in outputs])\n",
    "        all_preds = all_outputs.argmax(dim=1)\n",
    "        accuracy = (all_preds == all_labels).float().mean()\n",
    "        self.log(\"val_accuracy\", accuracy)\n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss(outputs, labels)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.test_step_outputs.append((loss, outputs, labels))\n",
    "        return loss, outputs, labels\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        outputs = self.test_step_outputs\n",
    "        avg_loss = torch.stack([x[0] for x in outputs]).mean()\n",
    "        self.log(\"avg_test_loss\", avg_loss)\n",
    "        \n",
    "        all_outputs = torch.cat([x[1] for x in outputs])\n",
    "        all_labels = torch.cat([x[2] for x in outputs])\n",
    "        all_preds = all_outputs.argmax(dim=1)\n",
    "        accuracy = (all_preds == all_labels).float().mean()\n",
    "        self.log(\"test_accuracy\", accuracy)\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, data, vocab):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.data[index][2])\n",
    "        line = self.data[index][1]\n",
    "        # convert characters to indices with unk token \n",
    "        line = [self.vocab.get(char, 1) for char in line]\n",
    "        \n",
    "        if len(line) > 100:\n",
    "            line = line[:100]\n",
    "        else:\n",
    "            line = line[:100] + [0] * (100 - len(line))\n",
    "            \n",
    "        return torch.tensor(line), torch.tensor(label)\n",
    "    \n",
    "train_dataset = SentimentDataset(train_data, vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = SentimentDataset(test_data, vocab)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dataset = SentimentDataset(test_data, vocab)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentcls = SentimentClassifier(len(vocab))\n",
    "PLSentimentClassifier = SentimentClassifierPL(sentcls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb.login()\n",
    "wandb_logger = WandbLogger(project=\"NLP\", name=\"Lec01_sentiment_classification_w_pl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpoint = ModelCheckpoint(monitor='val_loss', \n",
    "                             dirpath=\"checkpoints\", \n",
    "                             filename=\"sentiment-classifier-{epoch:02d}-{val_loss:.2f}\",\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=3, \n",
    "                     accelerator=\"gpu\",\n",
    "                     callbacks=[early_stopping, checkpoint],\n",
    "                     logger=wandb_logger\n",
    "                     ) # see https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=PLSentimentClassifier, \n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SentimentClassifierPL.load_from_checkpoint(\".\", \n",
    "                                                        sentiment_classifier=SentimentClassifier(len(vocab)))\n",
    "trainer.test(best_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
